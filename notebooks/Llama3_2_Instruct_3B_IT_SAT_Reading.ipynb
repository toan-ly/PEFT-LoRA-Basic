{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97NYN3e_6BcS"
      },
      "source": [
        "## **Install and import necessary libaries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO59tP-Bvion",
        "outputId": "401b8d02-fdda-405d-da2b-3934296b1325"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U datasets\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q -U loralib\n",
        "!pip install -q -U einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1g4cs-qYwjtO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig, GenerationConfig,\n",
        "    TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        ")\n",
        "from peft import (\n",
        "    LoraConfig, get_peft_model,\n",
        "    prepare_model_for_kbit_training\n",
        ")\n",
        "from huggingface_hub import login\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "3qUylpO1P3xA",
        "outputId": "25a2a37e-05c2-4734-9f0e-de3fbdfd0d54"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Log in to Hugging Face\n",
        "login(token=\"your_hf_token_here\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL3aZuZr6LRp"
      },
      "source": [
        "## **Load pretrained LLM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fp7ASGJtP3xB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        },
        "id": "5kFK18GDxMaW",
        "outputId": "91a5021d-f7f6-4727-80a3-b40ea28dc70b"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    quantization_config=bnb_config\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3IyFZsPP3xC"
      },
      "outputs": [],
      "source": [
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leNliYBZ0IqT"
      },
      "outputs": [],
      "source": [
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"up_proj\",\n",
        "        \"o_proj\",\n",
        "        \"k_proj\",\n",
        "        \"down_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"v_proj\"\n",
        "    ],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1ECaycSP3xD",
        "outputId": "16346c38-c4d1-4136-e849-3688a04027fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 24313856 || all params: 1827777536 || trainables%: 1.330241537665993\n"
          ]
        }
      ],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainables%: {100 * trainable_params / all_param}\"\n",
        "    )\n",
        "\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2tqt8jmP3xD",
        "outputId": "00952614-8499-4af0-e1ef-26f1d9ac65e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VRAM free: 18.08 GB\n"
          ]
        }
      ],
      "source": [
        "print(f\"VRAM free: {torch.cuda.mem_get_info()[0] / 1024**3:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY2I1hXZa4Qt"
      },
      "source": [
        "## **Test pretrained model performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhX68KkaP3xD"
      },
      "outputs": [],
      "source": [
        "from transformers import GenerationConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsN3DO8C0TFD",
        "outputId": "e7619bc0-eda2-4709-8a61-43a0ac488d4a"
      },
      "outputs": [],
      "source": [
        "generation_config = GenerationConfig(\n",
        "    max_new_tokens=50,\n",
        "    temperature=0.01,\n",
        "    do_sample=False,\n",
        "    num_return_sequences=1,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    repetition_penalty=1.3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B56-xXB6P3xE"
      },
      "outputs": [],
      "source": [
        "# Llama-3's official system prompt structure\n",
        "LLAMA3_SYSTEM_PROMPT = \"\"\"You are a helpful AI assistant developed by Meta. Respond safely and accurately.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5aDJcvm0PDj"
      },
      "outputs": [],
      "source": [
        "# Test pretrained model performance\n",
        "prompt = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": LLAMA3_SYSTEM_PROMPT\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"Analyze the given passage and question. Choose the best answer from the options below.\n",
        "\n",
        "### Passage:\n",
        "[This passage is adapted from George Eliot, Silas Marner. Originally published in 1861. Silas was a weaver and a notorious miser, but then the gold he had hoarded was stolen. Shortly after, Silas adopted a young child, Eppie, the daughter of an impoverished woman who had died suddenly.\n",
        "\n",
        "    Unlike the gold which needed nothing, and must\n",
        "be worshipped in close-locked solitude—which was\n",
        "hidden away from the daylight, was deaf to the song\n",
        "of birds, and started to no human tones—Eppie was a\n",
        "creature of endless claims and ever-growing desires,\n",
        "seeking and loving sunshine, and living sounds, and\n",
        "living movements; making trial of everything, with\n",
        "trust in new joy, and stirring the human kindness in\n",
        "all eyes that looked on her. The gold had kept his\n",
        "thoughts in an ever-repeated circle, leading to\n",
        "nothing beyond itself; but Eppie was an object\n",
        "compacted of changes and hopes that forced his\n",
        "thoughts onward, and carried them far away from\n",
        "their old eager pacing towards the same blank\n",
        "limit—carried them away to the new things that\n",
        "would come with the coming years, when Eppie\n",
        "would have learned to understand how her father\n",
        "Silas cared for her; and made him look for images of\n",
        "that time in the ties and charities that bound together\n",
        "the families of his neighbors. The gold had asked that\n",
        "he should sit weaving longer and longer, deafened\n",
        "and blinded more and more to all things except the\n",
        "monotony of his loom and the repetition of his web;\n",
        "but Eppie called him away from his weaving, and\n",
        "made him think all its pauses a holiday, reawakening\n",
        "his senses with her fresh life, even to the old\n",
        "winter-flies that came crawling forth in the early\n",
        "spring sunshine, and warming him into joy because\n",
        "she had joy.\n",
        "    And when the sunshine grew strong and lasting,\n",
        "so that the buttercups were thick in the meadows,\n",
        "Silas might be seen in the sunny mid-day, or in the\n",
        "late afternoon when the shadows were lengthening\n",
        "under the hedgerows, strolling out with uncovered\n",
        "head to carry Eppie beyond the Stone-pits to where\n",
        "the flowers grew, till they reached some favorite bank\n",
        "where he could sit down, while Eppie toddled to\n",
        "pluck the flowers, and make remarks to the winged\n",
        "things that murmured happily above the bright\n",
        "petals, calling “Dad-dad’s” attention continually by\n",
        "bringing him the flowers. Then she would turn her\n",
        "ear to some sudden bird-note, and Silas learned to\n",
        "please her by making signs of hushed stillness, that\n",
        "they might listen for the note to come again: so that\n",
        "when it came, she set up her small back and laughed\n",
        "with gurgling triumph. Sitting on the banks in this\n",
        "way, Silas began to look for the once familiar herbs\n",
        "again; and as the leaves, with their unchanged outline\n",
        "and markings, lay on his palm, there was a sense of\n",
        "crowding remembrances from which he turned away\n",
        "timidly, taking refuge in Eppie’s little world, that lay\n",
        "lightly on his enfeebled spirit.\n",
        "    As the child’s mind was growing into knowledge,\n",
        "his mind was growing into memory: as her life\n",
        "unfolded, his soul, long stupefied in a cold narrow\n",
        "prison, was unfolding too, and trembling gradually\n",
        "into full consciousness.\n",
        "    It was an influence which must gather force with\n",
        "every new year: the tones that stirred Silas’ heart\n",
        "grew articulate, and called for more distinct answers;\n",
        "shapes and sounds grew clearer for Eppie’s eyes and\n",
        "ears, and there was more that “Dad-dad” was\n",
        "imperatively required to notice and account for.\n",
        "Also, by the time Eppie was three years old, she\n",
        "developed a fine capacity for mischief, and for\n",
        "devising ingenious ways of being troublesome, which\n",
        "found much exercise, not only for Silas’ patience, but\n",
        "for his watchfulness and penetration. Sorely was poor\n",
        "Silas puzzled on such occasions by the incompatible\n",
        "demands of love.]\n",
        "\n",
        "### Question:\n",
        "Which statement best describes a technique the narrator uses to represent Silas's character before he adopted Eppie?\n",
        "\n",
        "### Choices:\n",
        "A) The narrator emphasizes Silas's former obsession with wealth by depicting his gold as requiring certain behaviors on his part.\n",
        "B) The narrator underscores Silas's former greed by describing his gold as seeming to reproduce on its own.\n",
        "C) The narrator hints at Silas's former antisocial attitude by contrasting his present behavior toward his neighbors with his past behavior toward them.\n",
        "D) The narrator demonstrates Silas's former lack of self-awareness by implying that he is unable to recall life before Eppie.\n",
        "\n",
        "Respond ONLY with the letter and full text of the correct answer choice.\"\"\"\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C8P1Qqcj0VIe",
        "outputId": "d668731b-180a-4d1e-c0a6-84dd63f08e45"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Apply chat template (text only)\n",
        "chat_text = tokenizer.apply_chat_template(\n",
        "    prompt,\n",
        "    add_generation_prompt=True,\n",
        "    tokenize=False\n",
        ")\n",
        "\n",
        "# Tokenize\n",
        "inputs = tokenizer(\n",
        "    chat_text,\n",
        "    return_tensors=\"pt\"\n",
        ").to(device)\n",
        "\n",
        "# Generate output\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        generation_config=generation_config,\n",
        "    )\n",
        "\n",
        "\n",
        "# Decode output\n",
        "output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "if \"<|assistant|>\" in output_text:\n",
        "    print(output_text.split(\"<|assistant|>\")[-1].strip())\n",
        "else:\n",
        "    print(output_text.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK7lUW10a9d5"
      },
      "source": [
        "## **Fine-tuning LLM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwPC_aBB6VXm"
      },
      "outputs": [],
      "source": [
        "data = load_dataset('emozilla/sat-reading')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImH26GW96vbB",
        "outputId": "f5dd5c46-8e30-41db-d991-de8e07751139"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'answer', 'requires_line', 'id'],\n",
              "        num_rows: 298\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'answer', 'requires_line', 'id'],\n",
              "        num_rows: 39\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'answer', 'requires_line', 'id'],\n",
              "        num_rows: 38\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnrdD8pZoOPx",
        "outputId": "8a7c9178-f769-40bd-a4e1-59097d36f35d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "datasets.dataset_dict.DatasetDict"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hVunfNU68i0",
        "outputId": "9042babb-ea0f-431e-f246-e643e2b26efa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'answer', 'requires_line', 'id'],\n",
              "    num_rows: 298\n",
              "})"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6Daio0eONzd",
        "outputId": "108cbe95-8a66-4372-c8e8-1d31d86a86c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAT READING COMPREHENSION TEST\n",
            "\n",
            "This passage is adapted from George Eliot, Silas Marner.\n",
            "Originally published in 1861. Silas was a weaver and a\n",
            "notorious miser, but then the gold he had hoarded was\n",
            "stolen. Shortly after, Silas adopted a young child, Eppie, the\n",
            "daughter of an impoverished woman who had died\n",
            "suddenly.\n",
            "\n",
            "    Unlike the gold which needed nothing, and must\n",
            "be worshipped in close-locked solitude—which was\n",
            "hidden away from the daylight, was deaf to the song\n",
            "of birds, and started to no human tones—Eppie was a\n",
            "creature of endless claims and ever-growing desires,\n",
            "seeking and loving sunshine, and living sounds, and\n",
            "living movements; making trial of everything, with\n",
            "trust in new joy, and stirring the human kindness in\n",
            "all eyes that looked on her. The gold had kept his\n",
            "thoughts in an ever-repeated circle, leading to\n",
            "nothing beyond itself; but Eppie was an object\n",
            "compacted of changes and hopes that forced his\n",
            "thoughts onward, and carried them far away from\n",
            "their old eager pacing towards the same blank\n",
            "limit—carried them away to the new things that\n",
            "would come with the coming years, when Eppie\n",
            "would have learned to understand how her father\n",
            "Silas cared for her; and made him look for images of\n",
            "that time in the ties and charities that bound together\n",
            "the families of his neighbors. The gold had asked that\n",
            "he should sit weaving longer and longer, deafened\n",
            "and blinded more and more to all things except the\n",
            "monotony of his loom and the repetition of his web;\n",
            "but Eppie called him away from his weaving, and\n",
            "made him think all its pauses a holiday, reawakening\n",
            "his senses with her fresh life, even to the old\n",
            "winter-flies that came crawling forth in the early\n",
            "spring sunshine, and warming him into joy because\n",
            "she had joy.\n",
            "    And when the sunshine grew strong and lasting,\n",
            "so that the buttercups were thick in the meadows,\n",
            "Silas might be seen in the sunny mid-day, or in the\n",
            "late afternoon when the shadows were lengthening\n",
            "under the hedgerows, strolling out with uncovered\n",
            "head to carry Eppie beyond the Stone-pits to where\n",
            "the flowers grew, till they reached some favorite bank\n",
            "where he could sit down, while Eppie toddled to\n",
            "pluck the flowers, and make remarks to the winged\n",
            "things that murmured happily above the bright\n",
            "petals, calling “Dad-dad’s” attention continually by\n",
            "bringing him the flowers. Then she would turn her\n",
            "ear to some sudden bird-note, and Silas learned to\n",
            "please her by making signs of hushed stillness, that\n",
            "they might listen for the note to come again: so that\n",
            "when it came, she set up her small back and laughed\n",
            "with gurgling triumph. Sitting on the banks in this\n",
            "way, Silas began to look for the once familiar herbs\n",
            "again; and as the leaves, with their unchanged outline\n",
            "and markings, lay on his palm, there was a sense of\n",
            "crowding remembrances from which he turned away\n",
            "timidly, taking refuge in Eppie’s little world, that lay\n",
            "lightly on his enfeebled spirit.\n",
            "    As the child’s mind was growing into knowledge,\n",
            "his mind was growing into memory: as her life\n",
            "unfolded, his soul, long stupefied in a cold narrow\n",
            "prison, was unfolding too, and trembling gradually\n",
            "into full consciousness.\n",
            "    It was an influence which must gather force with\n",
            "every new year: the tones that stirred Silas’ heart\n",
            "grew articulate, and called for more distinct answers;\n",
            "shapes and sounds grew clearer for Eppie’s eyes and\n",
            "ears, and there was more that “Dad-dad” was\n",
            "imperatively required to notice and account for.\n",
            "Also, by the time Eppie was three years old, she\n",
            "developed a fine capacity for mischief, and for\n",
            "devising ingenious ways of being troublesome, which\n",
            "found much exercise, not only for Silas’ patience, but\n",
            "for his watchfulness and penetration. Sorely was poor\n",
            "Silas puzzled on such occasions by the incompatible\n",
            "demands of love.\n",
            "\n",
            "\n",
            "\n",
            "Question 3:\n",
            "Which statement best describes a technique the narrator uses to represent Silas’s character before he adopted Eppie?\n",
            "A) The narrator emphasizes Silas’s former obsession with wealth by depicting his gold as requiring certain behaviors on his part.\n",
            "B) The narrator underscores Silas’s former greed by describing his gold as seeming to reproduce on its own.\n",
            "C) The narrator hints at Silas’s former antisocial attitude by contrasting his present behavior toward his neighbors with his past behavior toward them.\n",
            "D) The narrator demonstrates Silas’s former lack of self-awareness by implying that he is unable to recall life before Eppie.\n",
            "\n",
            "Answer:\n"
          ]
        }
      ],
      "source": [
        "print(data[\"train\"]['text'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0UKWAUSMAsH",
        "outputId": "838e3d17-8947-4f49-826e-686a360460fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A\n"
          ]
        }
      ],
      "source": [
        "print(data[\"train\"][\"answer\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRZPr4jHP3xG"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def extract_sections(text):\n",
        "    \"\"\"Parse raw SAT text into structured sections\"\"\"\n",
        "    sections = {\n",
        "        'passage': '',\n",
        "        'question': '',\n",
        "        'choices': [],\n",
        "        'answer_letter': ''\n",
        "    }\n",
        "\n",
        "    answer_part = text.split('Answer:')[-1].strip()\n",
        "    sections['answer_letter'] = answer_part[0] if answer_part else ''\n",
        "\n",
        "    content = text.split('SAT READING COMPREHENSION TEST')[-1].split('Answer:')[0]\n",
        "    blocks = [b.strip() for b in content.split('\\n\\n') if b.strip()]\n",
        "\n",
        "    passage_lines = []\n",
        "    for line in blocks:\n",
        "        if line.startswith('Question'):\n",
        "            break\n",
        "        passage_lines.append(line)\n",
        "    sections['passage'] = '\\n'.join(passage_lines).strip()\n",
        "\n",
        "    for block in blocks:\n",
        "        if block.startswith('Question'):\n",
        "            lines = block.split('\\n')\n",
        "            question_lines = []\n",
        "            choice_lines = []\n",
        "\n",
        "            for line in lines[1:]:\n",
        "                if re.match(r'^[A-D]\\)', line.strip()):\n",
        "                    choice_lines.append(line.strip())\n",
        "                else:\n",
        "                    question_lines.append(line.strip())\n",
        "\n",
        "            sections['question'] = ' '.join(question_lines).strip()\n",
        "            sections['choices'] = choice_lines\n",
        "\n",
        "    return sections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcnc_sHKP3xH"
      },
      "outputs": [],
      "source": [
        "def map_answer(text, letter):\n",
        "    \"\"\"Match answer letter with full choice text\"\"\"\n",
        "    sections = extract_sections(text)\n",
        "    for choice in sections['choices']:\n",
        "        if choice.startswith(f\"{letter})\"):\n",
        "            return choice\n",
        "    return letter  # Fallback if not found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMxfJFHEv8J7"
      },
      "outputs": [],
      "source": [
        "def generate_prompt(text, answer_letter):\n",
        "    sections = extract_sections(text)\n",
        "\n",
        "    choices_text = '\\n'.join(sections['choices'])\n",
        "\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": LLAMA3_SYSTEM_PROMPT\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Read the passage and answer the question.\n",
        "\n",
        "### Passage:\n",
        "{sections['passage']}\n",
        "\n",
        "### Question:\n",
        "{sections['question']}\n",
        "\n",
        "### Choices:\n",
        "{choices_text}\n",
        "\n",
        "Respond with ONLY the letter and full text of the correct answer.\"\"\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": map_answer(text, answer_letter)\n",
        "        }\n",
        "    ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-GbfsEOZ-T_"
      },
      "outputs": [],
      "source": [
        "def generate_and_tokenize_prompt(user_input, answer):\n",
        "    try:\n",
        "        full_prompt = generate_prompt(user_input, answer)\n",
        "\n",
        "        prompt_str = tokenizer.apply_chat_template(\n",
        "            full_prompt,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=False\n",
        "        )\n",
        "\n",
        "        tokenized = tokenizer(\n",
        "            prompt_str,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=1506,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        input_ids = tokenized[\"input_ids\"][0]\n",
        "        labels = input_ids.clone()\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": tokenized[\"attention_mask\"][0],\n",
        "            \"labels\": labels\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing sample: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzkPgPviP3xH",
        "outputId": "49907b7b-acd3-41ed-e1ea-7ff4bcb55089"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Generated Prompt ===\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 21 Apr 2025\n",
            "\n",
            "You are a helpful AI assistant developed by Meta. Respond safely and accurately.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Read the passage and answer the question.\n",
            "\n",
            "### Passage:\n",
            "This passage is adapted from George Eliot, Silas Marner.\n",
            "Originally published in 1861. Silas was a weaver and a\n",
            "notorious miser, but then the gold he had hoarded was\n",
            "stolen. Shortly after, Silas adopted a young child, Eppie, the\n",
            "daughter of an impoverished woman who had died\n",
            "suddenly.\n",
            "Unlike the gold which needed nothing, and must\n",
            "be worshipped in close-locked solitude—which was\n",
            "hidden away from the daylight, was deaf to the song\n",
            "of birds, and started to no human tones—Eppie was a\n",
            "creature of endless claims and ever-growing desires,\n",
            "seeking and loving sunshine, and living sounds, and\n",
            "living movements; making trial of everything, with\n",
            "trust in new joy, and stirring the human kindness in\n",
            "all eyes that looked on her. The gold had kept his\n",
            "thoughts in an ever-repeated circle, leading to\n",
            "nothing beyond itself; but Eppie was an object\n",
            "compacted of changes and hopes that forced his\n",
            "thoughts onward, and carried them far away from\n",
            "their old eager pacing towards the same blank\n",
            "limit—carried them away to the new things that\n",
            "would come with the coming years, when Eppie\n",
            "would have learned to understand how her father\n",
            "Silas cared for her; and made him look for images of\n",
            "that time in the ties and charities that bound together\n",
            "the families of his neighbors. The gold had asked that\n",
            "he should sit weaving longer and longer, deafened\n",
            "and blinded more and more to all things except the\n",
            "monotony of his loom and the repetition of his web;\n",
            "but Eppie called him away from his weaving, and\n",
            "made him think all its pauses a holiday, reawakening\n",
            "his senses with her fresh life, even to the old\n",
            "winter-flies that came crawling forth in the early\n",
            "spring sunshine, and warming him into joy because\n",
            "she had joy.\n",
            "    And when the sunshine grew strong and lasting,\n",
            "so that the buttercups were thick in the meadows,\n",
            "Silas might be seen in the sunny mid-day, or in the\n",
            "late afternoon when the shadows were lengthening\n",
            "under the hedgerows, strolling out with uncovered\n",
            "head to carry Eppie beyond the Stone-pits to where\n",
            "the flowers grew, till they reached some favorite bank\n",
            "where he could sit down, while Eppie toddled to\n",
            "pluck the flowers, and make remarks to the winged\n",
            "things that murmured happily above the bright\n",
            "petals, calling “Dad-dad’s” attention continually by\n",
            "bringing him the flowers. Then she would turn her\n",
            "ear to some sudden bird-note, and Silas learned to\n",
            "please her by making signs of hushed stillness, that\n",
            "they might listen for the note to come again: so that\n",
            "when it came, she set up her small back and laughed\n",
            "with gurgling triumph. Sitting on the banks in this\n",
            "way, Silas began to look for the once familiar herbs\n",
            "again; and as the leaves, with their unchanged outline\n",
            "and markings, lay on his palm, there was a sense of\n",
            "crowding remembrances from which he turned away\n",
            "timidly, taking refuge in Eppie’s little world, that lay\n",
            "lightly on his enfeebled spirit.\n",
            "    As the child’s mind was growing into knowledge,\n",
            "his mind was growing into memory: as her life\n",
            "unfolded, his soul, long stupefied in a cold narrow\n",
            "prison, was unfolding too, and trembling gradually\n",
            "into full consciousness.\n",
            "    It was an influence which must gather force with\n",
            "every new year: the tones that stirred Silas’ heart\n",
            "grew articulate, and called for more distinct answers;\n",
            "shapes and sounds grew clearer for Eppie’s eyes and\n",
            "ears, and there was more that “Dad-dad” was\n",
            "imperatively required to notice and account for.\n",
            "Also, by the time Eppie was three years old, she\n",
            "developed a fine capacity for mischief, and for\n",
            "devising ingenious ways of being troublesome, which\n",
            "found much exercise, not only for Silas’ patience, but\n",
            "for his watchfulness and penetration. Sorely was poor\n",
            "Silas puzzled on such occasions by the incompatible\n",
            "demands of love.\n",
            "\n",
            "### Question:\n",
            "Which statement best describes a technique the narrator uses to represent Silas’s character before he adopted Eppie?\n",
            "\n",
            "### Choices:\n",
            "A) The narrator emphasizes Silas’s former obsession with wealth by depicting his gold as requiring certain behaviors on his part.\n",
            "B) The narrator underscores Silas’s former greed by describing his gold as seeming to reproduce on its own.\n",
            "C) The narrator hints at Silas’s former antisocial attitude by contrasting his present behavior toward his neighbors with his past behavior toward them.\n",
            "D) The narrator demonstrates Silas’s former lack of self-awareness by implying that he is unable to recall life before Eppie.\n",
            "\n",
            "Respond with ONLY the letter and full text of the correct answer.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "A) The narrator emphasizes Silas’s former obsession with wealth by depicting his gold as requiring certain behaviors on his part.<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "sample_text = data[\"train\"]['text'][0]\n",
        "sample_answer = data[\"train\"]['answer'][0]\n",
        "\n",
        "example_messages = generate_prompt(sample_text, sample_answer)\n",
        "prompt_text = tokenizer.apply_chat_template(\n",
        "    example_messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=False\n",
        ")\n",
        "print(\"=== Generated Prompt ===\")\n",
        "print(prompt_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54rwNsHCaTJL",
        "outputId": "b58fb398-e74c-4ef3-8d35-d2d2378b1d4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Tokenized Sample ===\n",
            "Input IDs shape: torch.Size([1506])\n",
            "Sample decoded back:\n",
            "system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 21 Apr 2025\n",
            "\n",
            "You are a helpful AI assistant developed by Meta. Respond safely and accurately.user\n",
            "\n",
            "Read the passage and answer the question.\n",
            "\n",
            "### Passage:\n",
            "This passage is adapted from George Eliot, Silas Marner.\n",
            "Originally published in 1861. Silas was a weaver and a\n",
            "notorious miser, but then the gold he had hoarded was\n",
            "stolen. Shortly after, Silas adopted a young child, Eppie, the\n",
            "daughter of an impoverished woman who had died\n",
            "suddenly.\n",
            "Unlike the gold which needed nothing, and must\n",
            "be worshipped in close-locked solitude—which was\n",
            "hidden away from the daylight, was deaf to the song\n",
            "of birds, and started to no human tones—Eppie was a\n",
            "creature of endless claims and ever-growing desires,\n",
            "seeking and loving sunshine, and living sounds, and\n",
            "living movements; making trial of everything, with\n",
            "trust in new joy, and stirring the human kindness in\n",
            "all eyes that looked on her. The gold had kept his\n",
            "thoughts in an ever-repeated circle, leading to\n",
            "nothing beyond itself; but Eppie was an object\n",
            "compacted of changes and hopes that forced his\n",
            "thoughts onward, and carried them far away from\n",
            "their old eager pacing towards the same blank\n",
            "limit—carried them away to the new things that\n",
            "would come with the coming years, when Eppie\n",
            "would have learned to understand how her father\n",
            "Silas cared for her; and made him look for images of\n",
            "that time in the ties and charities that bound together\n",
            "the families of his neighbors. The gold had asked that\n",
            "he should sit weaving longer and longer, deafened\n",
            "and blinded more and more to all things except the\n",
            "monotony of his loom and the repetition of his web;\n",
            "but Eppie called him away from his weaving, and\n",
            "made him think all its pauses a holiday, reawakening\n",
            "his senses with her fresh life, even to the old\n",
            "winter-flies that came crawling forth in the early\n",
            "spring sunshine, and warming him into joy because\n",
            "she had joy.\n",
            "    And when the sunshine grew strong and lasting,\n",
            "so that the buttercups were thick in the meadows,\n",
            "Silas might be seen in the sunny mid-day, or in the\n",
            "late afternoon when the shadows were lengthening\n",
            "under the hedgerows, strolling out with uncovered\n",
            "head to carry Eppie beyond the Stone-pits to where\n",
            "the flowers grew, till they reached some favorite bank\n",
            "where he could sit down, while Eppie toddled to\n",
            "pluck the flowers, and make remarks to the winged\n",
            "things that murmured happily above the bright\n",
            "petals, calling “Dad-dad’s” attention continually by\n",
            "bringing him the flowers. Then she would turn her\n",
            "ear to some sudden bird-note, and Silas learned to\n",
            "please her by making signs of hushed stillness, that\n",
            "they might listen for the note to come again: so that\n",
            "when it came, she set up her small back and laughed\n",
            "with gurgling triumph. Sitting on the banks in this\n",
            "way, Silas began to look for the once familiar herbs\n",
            "again; and as the leaves, with their unchanged outline\n",
            "and markings, lay on his palm, there was a sense of\n",
            "crowding remembrances from which he turned away\n",
            "timidly, taking refuge in Eppie’s little world, that lay\n",
            "lightly on his enfeebled spirit.\n",
            "    As the child’s mind was growing into knowledge,\n",
            "his mind was growing into memory: as her life\n",
            "unfolded, his soul, long stupefied in a cold narrow\n",
            "prison, was unfolding too, and trembling gradually\n",
            "into full consciousness.\n",
            "    It was an influence which must gather force with\n",
            "every new year: the tones that stirred Silas’ heart\n",
            "grew articulate, and called for more distinct answers;\n",
            "shapes and sounds grew clearer for Eppie’s eyes and\n",
            "ears, and there was more that “Dad-dad” was\n",
            "imperatively required to notice and account for.\n",
            "Also, by the time Eppie was three years old, she\n",
            "developed a fine capacity for mischief, and for\n",
            "devising ingenious ways of being troublesome, which\n",
            "found much exercise, not only for Silas’ patience, but\n",
            "for his watchfulness and penetration. Sorely was poor\n",
            "Silas puzzled on such occasions by the incompatible\n",
            "demands of love.\n",
            "\n",
            "### Question:\n",
            "Which statement best describes a technique the narrator uses to represent Silas’s character before he adopted Eppie?\n",
            "\n",
            "### Choices:\n",
            "A) The narrator emphasizes Silas’s former obsession with wealth by depicting his gold as requiring certain behaviors on his part.\n",
            "B) The narrator underscores Silas’s former greed by describing his gold as seeming to reproduce on its own.\n",
            "C) The narrator hints at Silas’s former antisocial attitude by contrasting his present behavior toward his neighbors with his past behavior toward them.\n",
            "D) The narrator demonstrates Silas’s former lack of self-awareness by implying that he is unable to recall life before Eppie.\n",
            "\n",
            "Respond with ONLY the letter and full text of the correct answer.assistant\n",
            "\n",
            "A) The narrator emphasizes Silas’s former obsession with wealth by depicting his gold as requiring certain behaviors on his part.\n"
          ]
        }
      ],
      "source": [
        "tokenized_sample = generate_and_tokenize_prompt(sample_text, sample_answer)\n",
        "if tokenized_sample:\n",
        "    print(\"\\n=== Tokenized Sample ===\")\n",
        "    print(f\"Input IDs shape: {tokenized_sample['input_ids'].shape}\")\n",
        "    print(f\"Sample decoded back:\")\n",
        "    print(tokenizer.decode(tokenized_sample['input_ids'], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uoivys5iN3U5",
        "outputId": "72a09e0b-24ec-4670-ec2e-cca1382921cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 298/298 [00:00<00:00, 335.27it/s]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "training_samples = []\n",
        "for sample in tqdm(data['train']):\n",
        "    try:\n",
        "        # preprocessing data\n",
        "        processed_text = sample['text'].replace('SAT READING COMPREHENSION TEST', '').strip()\n",
        "        processed_answer = map_answer(sample['text'], sample['answer'].strip())\n",
        "\n",
        "        # create sample\n",
        "        tokenized_sample = generate_and_tokenize_prompt(processed_text, processed_answer)\n",
        "        if tokenized_sample is not None:\n",
        "            training_samples.append(tokenized_sample)\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping invalid sample: {e}\")\n",
        "\n",
        "training_samples = [s for s in training_samples if s is not None]\n",
        "\n",
        "train_samples, val_samples = train_test_split(training_samples, test_size=0.1, random_state=42)\n",
        "train_dataset = Dataset.from_list(train_samples)\n",
        "eval_dataset = Dataset.from_list(val_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaPiMgsl78ol",
        "outputId": "ef8d40c0-3575-4d2e-a594-e2fd74b0aee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min: 1506, Max: 1506, Avg: 1506.0\n"
          ]
        }
      ],
      "source": [
        "# check length samples\n",
        "train_lengths = [len(x[\"input_ids\"]) for x in train_dataset]\n",
        "eval_lengths = [len(x[\"input_ids\"]) for x in eval_dataset]\n",
        "all_lengths = train_lengths + eval_lengths\n",
        "print(f\"Min: {min(all_lengths)}, Max: {max(all_lengths)}, Avg: {sum(all_lengths)/len(all_lengths):.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcpuJU9_bDJu"
      },
      "source": [
        "### **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta_c_ISEP3xI"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainerCallback\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "\n",
        "class LogLossCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.console = Console()\n",
        "        self.table = Table(show_header=True, header_style=\"bold magenta\")\n",
        "        self.table.add_column(\"Step\", justify=\"right\")\n",
        "        self.table.add_column(\"Training Loss\", justify=\"right\")\n",
        "        self.logged_steps = set()\n",
        "\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs is not None and \"loss\" in logs:\n",
        "            step = state.global_step\n",
        "            if step not in self.logged_steps:\n",
        "                loss = logs[\"loss\"]\n",
        "                self.table.add_row(str(step), f\"{loss:.6f}\")\n",
        "                self.logged_steps.add(step)\n",
        "\n",
        "                if step % 10 == 0:\n",
        "                    self.console.print(self.table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dW973laKADUH",
        "outputId": "9b25c740-cf38-4baa-8dbe-c6f0483570ba"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    save_total_limit=3,\n",
        "    logging_steps=10,\n",
        "    output_dir=\"llama3-8b-sat-reading\",\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.05,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=50,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"loss\",\n",
        "    greater_is_better=False,\n",
        "    report_to=\"none\",\n",
        "    remove_unused_columns=False\n",
        ")\n",
        "\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False,\n",
        "    pad_to_multiple_of=8\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    callbacks=[LogLossCallback()]\n",
        ")\n",
        "\n",
        "# Quantization-aware training settings\n",
        "model.config.use_cache = False\n",
        "model.enable_input_require_grads()\n",
        "model = torch.compile(model)\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgFsBEbnIUw-"
      },
      "source": [
        "### **Test prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3J4kyeKeQ8B",
        "outputId": "fc7e92a0-1bf0-4993-bc0c-03966b4b7012"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAT READING COMPREHENSION TEST\n",
            "\n",
            "This passage is adapted from Mary Helen Stefaniak, The\n",
            "Cailiffs of Baghdad, Georgia: A Novel. ©2010 by Mary Helen\n",
            "Stefaniak.\n",
            "\n",
            "    Miss Grace Spivey arrived in Threestep, Georgia,\n",
            "in August 1938. She stepped off the train wearing a\n",
            "pair of thick-soled boots suitable for hiking, a navy\n",
            "Line blue dress, and a little white tam that rode the waves\n",
            "of her red hair at a gravity-defying angle. August was\n",
            "a hellish month to step off the train in Georgia,\n",
            "although it was nothing, she said, compared to the\n",
            "119 degrees that greeted her when she arrived one\n",
            "time in Timbuktu, which, she assured us, was a real\n",
            "place in Africa. I believe her remark irritated some of\n",
            "the people gathered to welcome her on the burned\n",
            "grass alongside the tracks. When folks are sweating\n",
            "through their shorts, they don’t like to hear that this\n",
            "is nothing compared to someplace else. Irritated or\n",
            "not, the majority of those present were inclined to see\n",
            "the arrival of the new schoolteacher in a positive\n",
            "light. Hard times were still upon us in 1938, but, like\n",
            "my momma said, “We weren’t no poorer than we’d\n",
            "ever been,” and the citizens of Threestep were in the\n",
            "mood for a little excitement.\n",
            "   Miss Spivey looked like just the right person to\n",
            "give it to them. She was, by almost anyone’s\n",
            "standards, a woman of the world. She’d gone to\n",
            "boarding schools since she was six years old; she’d\n",
            "studied French in Paris and drama in London; and\n",
            "during what she called a “fruitful intermission” in her\n",
            "formal education, she had traveled extensively in the\n",
            "Near East and Africa with a friend of her\n",
            "grandmother’s, one Janet Miller, who was a medical\n",
            "doctor from Nashville, Tennessee. After her travels\n",
            "with Dr. Miller, Miss Spivey continued her education\n",
            "by attending Barnard College in New York City. She\n",
            "told us all that at school the first day. When my little\n",
            "brother Ralphord asked what did she study at\n",
            "Barnyard College, Miss Spivey explained that\n",
            "Barnard, which she wrote on the blackboard, was the\n",
            "sister school of Columbia University, of which, she\n",
            "expected, we all had heard.\n",
            "    It was there, she told us, in the midst of trying to\n",
            "find her true mission in life, that she wandered one\n",
            "afternoon into a lecture by the famous John Dewey,\n",
            "who was talking about his famous book, Democracy\n",
            "and Education. Professor Dewey was in his seventies\n",
            "by then, Miss Spivey said, but he still liked to chat\n",
            "with students after a lecture—especially female\n",
            "students, she added—sometimes over coffee, and see\n",
            "in their eyes the fire his words could kindle. It was\n",
            "after this lecture and subsequent coffee that Miss\n",
            "Spivey had marched to the Teacher’s College and\n",
            "signed up, all aflame. Two years later, she told a\n",
            "cheery blue-suited woman from the WPA1 that she\n",
            "wanted to bring democracy and education to the\n",
            "poorest, darkest, most remote and forgotten corner\n",
            "of America.\n",
            "    They sent her to Threestep, Georgia.\n",
            "    Miss Spivey paused there for questions, avoiding\n",
            "my brother Ralphord’s eye.\n",
            "    What we really wanted to know about—all\n",
            "twenty-six of us across seven grade levels in the one\n",
            "room—was the pearly white button hanging on a\n",
            "string in front of the blackboard behind the teacher’s\n",
            "desk up front. That button on a string was something\n",
            "new. When Mavis Davis (the only bona fide seventh\n",
            "grader, at age thirteen) asked what it was for, Miss\n",
            "Spivey gave the string a tug, and to our astonishment,\n",
            "the whole world—or at least a wrinkled map of\n",
            "it—unfolded before our eyes. Her predecessor, Miss\n",
            "Chandler, had never once made use of that map,\n",
            "which was older than our fathers, and until that\n",
            "moment, not a one of us knew it was there.\n",
            "    Miss Spivey showed us on the map how she and\n",
            "Dr. Janet Miller had sailed across the Atlantic Ocean\n",
            "and past the Rock of Gibraltar into the\n",
            "Mediterranean Sea. Using the end of a ruler, she\n",
            "gently tapped such places as Morocco and Tunis and\n",
            "Algiers to mark their route along the top of Africa.\n",
            "They spent twenty hours on the train to Baghdad, she\n",
            "said, swathed in veils against the sand that crept in\n",
            "every crack and crevice.\n",
            "    “And can you guess what we saw from the train?”\n",
            "Miss Spivey asked. We could not. “Camels!” she said.\n",
            "“We saw a whole caravan of camels.” She looked\n",
            "around the room, waiting for us to be amazed and\n",
            "delighted at the thought.\n",
            "    We all hung there for a minute, thinking hard,\n",
            "until Mavis Davis spoke up.\n",
            "    “She means like the three kings rode to\n",
            "Bethlehem,” Mavis said, and she folded her hands\n",
            "smugly on her seventh-grade desk in the back of the\n",
            "room.\n",
            "    Miss Spivey made a mistake right then. Instead of\n",
            "beaming upon Mavis the kind of congratulatory\n",
            "smile that old Miss Chandler would have bestowed\n",
            "on her for having enlightened the rest of us, Miss\n",
            "Spivey simply said, “That’s right.”\n",
            "\n",
            "\n",
            "\n",
            "Question 7:\n",
            "In the third paragraph, what is the narrator most likely suggesting by describing Miss Spivey as having “wandered” (line 40) in one situation and “marched” (line 49) in another situation?\n",
            "A) Dewey, knowing Miss Spivey wasn’t very confident in her ability to teach, instilled in her a sense of determination.\n",
            "B) Talking with Dewey over coffee made Miss Spivey realize how excited she was to teach in the poorest, most remote corner of America.\n",
            "C) After two years spent studying, Miss Spivey was anxious to start teaching and be in charge of her own classroom.\n",
            "D) Miss Spivey’s initial encounter with Dewey’s ideas was somewhat accidental but ultimately motivated her to decisive action.\n",
            "\n",
            "Answer:\n"
          ]
        }
      ],
      "source": [
        "print(data[\"test\"]['text'][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT3R6GyPP3xJ",
        "outputId": "90be7d06-e606-4531-a211-e8b90df9e0f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ground truth:  D\n"
          ]
        }
      ],
      "source": [
        "print(\"Ground truth: \", data[\"test\"]['answer'][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWMAVb2qfDqj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import re\n",
        "from transformers import GenerationConfig\n",
        "\n",
        "generation_config = GenerationConfig(\n",
        "    max_new_tokens=64,\n",
        "    temperature=0.0,\n",
        "    top_p=1.0,\n",
        "    do_sample=False,\n",
        "    repetition_penalty=1.0,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    pad_token_id=tokenizer.pad_token_id\n",
        ")\n",
        "\n",
        "def extract_answer(output_text):\n",
        "    if \"<|assistant|>\" in output_text:\n",
        "        answer_part = output_text.split(\"<|assistant|>\")[-1].strip()\n",
        "    else:\n",
        "        answer_part = output_text.split(\"assistant\")[-1].strip()\n",
        "\n",
        "    match = re.search(r\"^([A-D])\\)\\s*([^\\n\\(]+)\", answer_part, re.MULTILINE)\n",
        "\n",
        "    if match:\n",
        "        return f\"{match.group(1)}) {match.group(2).strip()}\"\n",
        "    else:\n",
        "        clean_lines = [line for line in answer_part.split('\\n') if not line.startswith('**')]\n",
        "        return clean_lines[0].strip() if clean_lines else answer_part\n",
        "\n",
        "def format_test_prompt(text, answer_letter=None):\n",
        "    \"\"\"Format input text as chat conversation (for prediction or test)\"\"\"\n",
        "    sections = extract_sections(text)\n",
        "\n",
        "    # Build choices block\n",
        "    choices_text = '\\n'.join(sections['choices'])\n",
        "\n",
        "    user_prompt = f\"\"\"Read the passage and answer the question.\n",
        "\n",
        "### Passage:\n",
        "{sections['passage']}\n",
        "\n",
        "### Question:\n",
        "{sections['question']}\n",
        "\n",
        "### Choices:\n",
        "{choices_text}\n",
        "\n",
        "Respond with ONLY the letter and full text of the correct answer.\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": LLAMA3_SYSTEM_PROMPT\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_prompt\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    if answer_letter:\n",
        "        messages.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": map_answer(text, answer_letter)\n",
        "        })\n",
        "\n",
        "    return messages\n",
        "\n",
        "def predict(text):\n",
        "    messages = format_test_prompt(text)\n",
        "\n",
        "    prompt_text = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=False\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            generation_config=generation_config\n",
        "        )\n",
        "\n",
        "    # Decode\n",
        "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # === DEBUG ===\n",
        "    print(\"=== Full Decoded Output ===\")\n",
        "    print(output_text)\n",
        "\n",
        "    # Only answer\n",
        "    return extract_answer(output_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwRjpKXOP3xR",
        "outputId": "fecd46d5-e850-45f1-cfc9-866c7ec95ffa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Full Decoded Output ===\n",
            "system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 21 Apr 2025\n",
            "\n",
            "You are a helpful AI assistant developed by Meta. Respond safely and accurately.user\n",
            "\n",
            "Read the passage and answer the question.\n",
            "\n",
            "### Passage:\n",
            "This passage is adapted from Mary Helen Stefaniak, The\n",
            "Cailiffs of Baghdad, Georgia: A Novel. ©2010 by Mary Helen\n",
            "Stefaniak.\n",
            "Miss Grace Spivey arrived in Threestep, Georgia,\n",
            "in August 1938. She stepped off the train wearing a\n",
            "pair of thick-soled boots suitable for hiking, a navy\n",
            "Line blue dress, and a little white tam that rode the waves\n",
            "of her red hair at a gravity-defying angle. August was\n",
            "a hellish month to step off the train in Georgia,\n",
            "although it was nothing, she said, compared to the\n",
            "119 degrees that greeted her when she arrived one\n",
            "time in Timbuktu, which, she assured us, was a real\n",
            "place in Africa. I believe her remark irritated some of\n",
            "the people gathered to welcome her on the burned\n",
            "grass alongside the tracks. When folks are sweating\n",
            "through their shorts, they don’t like to hear that this\n",
            "is nothing compared to someplace else. Irritated or\n",
            "not, the majority of those present were inclined to see\n",
            "the arrival of the new schoolteacher in a positive\n",
            "light. Hard times were still upon us in 1938, but, like\n",
            "my momma said, “We weren’t no poorer than we’d\n",
            "ever been,” and the citizens of Threestep were in the\n",
            "mood for a little excitement.\n",
            "   Miss Spivey looked like just the right person to\n",
            "give it to them. She was, by almost anyone’s\n",
            "standards, a woman of the world. She’d gone to\n",
            "boarding schools since she was six years old; she’d\n",
            "studied French in Paris and drama in London; and\n",
            "during what she called a “fruitful intermission” in her\n",
            "formal education, she had traveled extensively in the\n",
            "Near East and Africa with a friend of her\n",
            "grandmother’s, one Janet Miller, who was a medical\n",
            "doctor from Nashville, Tennessee. After her travels\n",
            "with Dr. Miller, Miss Spivey continued her education\n",
            "by attending Barnard College in New York City. She\n",
            "told us all that at school the first day. When my little\n",
            "brother Ralphord asked what did she study at\n",
            "Barnyard College, Miss Spivey explained that\n",
            "Barnard, which she wrote on the blackboard, was the\n",
            "sister school of Columbia University, of which, she\n",
            "expected, we all had heard.\n",
            "    It was there, she told us, in the midst of trying to\n",
            "find her true mission in life, that she wandered one\n",
            "afternoon into a lecture by the famous John Dewey,\n",
            "who was talking about his famous book, Democracy\n",
            "and Education. Professor Dewey was in his seventies\n",
            "by then, Miss Spivey said, but he still liked to chat\n",
            "with students after a lecture—especially female\n",
            "students, she added—sometimes over coffee, and see\n",
            "in their eyes the fire his words could kindle. It was\n",
            "after this lecture and subsequent coffee that Miss\n",
            "Spivey had marched to the Teacher’s College and\n",
            "signed up, all aflame. Two years later, she told a\n",
            "cheery blue-suited woman from the WPA1 that she\n",
            "wanted to bring democracy and education to the\n",
            "poorest, darkest, most remote and forgotten corner\n",
            "of America.\n",
            "    They sent her to Threestep, Georgia.\n",
            "    Miss Spivey paused there for questions, avoiding\n",
            "my brother Ralphord’s eye.\n",
            "    What we really wanted to know about—all\n",
            "twenty-six of us across seven grade levels in the one\n",
            "room—was the pearly white button hanging on a\n",
            "string in front of the blackboard behind the teacher’s\n",
            "desk up front. That button on a string was something\n",
            "new. When Mavis Davis (the only bona fide seventh\n",
            "grader, at age thirteen) asked what it was for, Miss\n",
            "Spivey gave the string a tug, and to our astonishment,\n",
            "the whole world—or at least a wrinkled map of\n",
            "it—unfolded before our eyes. Her predecessor, Miss\n",
            "Chandler, had never once made use of that map,\n",
            "which was older than our fathers, and until that\n",
            "moment, not a one of us knew it was there.\n",
            "    Miss Spivey showed us on the map how she and\n",
            "Dr. Janet Miller had sailed across the Atlantic Ocean\n",
            "and past the Rock of Gibraltar into the\n",
            "Mediterranean Sea. Using the end of a ruler, she\n",
            "gently tapped such places as Morocco and Tunis and\n",
            "Algiers to mark their route along the top of Africa.\n",
            "They spent twenty hours on the train to Baghdad, she\n",
            "said, swathed in veils against the sand that crept in\n",
            "every crack and crevice.\n",
            "    “And can you guess what we saw from the train?”\n",
            "Miss Spivey asked. We could not. “Camels!” she said.\n",
            "“We saw a whole caravan of camels.” She looked\n",
            "around the room, waiting for us to be amazed and\n",
            "delighted at the thought.\n",
            "    We all hung there for a minute, thinking hard,\n",
            "until Mavis Davis spoke up.\n",
            "    “She means like the three kings rode to\n",
            "Bethlehem,” Mavis said, and she folded her hands\n",
            "smugly on her seventh-grade desk in the back of the\n",
            "room.\n",
            "    Miss Spivey made a mistake right then. Instead of\n",
            "beaming upon Mavis the kind of congratulatory\n",
            "smile that old Miss Chandler would have bestowed\n",
            "on her for having enlightened the rest of us, Miss\n",
            "Spivey simply said, “That’s right.”\n",
            "\n",
            "### Question:\n",
            "In the passage, Threestep is mainly presented as a\n",
            "\n",
            "### Choices:\n",
            "A) summer retreat for vacationers.\n",
            "B) small rural town.\n",
            "C) town that is home to a prominent university.\n",
            "D) comfortable suburb.\n",
            "\n",
            "Respond with ONLY the letter and full text of the correct answer.assistant\n",
            "\n",
            "B) small rural town.\n",
            "\n",
            "=== Final Result ===\n",
            "[Model Prediction]\n",
            "B) small rural town.\n",
            "\n",
            "[Ground Truth]\n",
            "B) small rural town.\n"
          ]
        }
      ],
      "source": [
        "test_sample_idx = 4\n",
        "input_text = data[\"test\"]['text'][test_sample_idx]\n",
        "true_answer = data[\"test\"]['answer'][test_sample_idx]\n",
        "\n",
        "predicted_answer = predict(input_text)\n",
        "\n",
        "true_answer_full = map_answer(input_text, true_answer)\n",
        "\n",
        "print(\"\\n=== Final Result ===\")\n",
        "print(f\"[Model Prediction]\\n{predicted_answer}\")\n",
        "print(f\"\\n[Ground Truth]\\n{true_answer_full}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHAv8F09P3xR"
      },
      "source": [
        "## **Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "em6Nz3thP3xR"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate(test_dataset, max_samples=None):\n",
        "    \"\"\"\n",
        "    Evaluate model accuracy on test set\n",
        "    Args:\n",
        "        test_dataset: Dataset object containing 'text' and 'answer'\n",
        "        max_samples: Optional limit for quick testing\n",
        "    \"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    wrong_samples = []\n",
        "\n",
        "    # Process samples with progress bar\n",
        "    for idx in tqdm(range(len(test_dataset[:max_samples]['text']))):\n",
        "        try:\n",
        "            text = test_dataset['text'][idx]\n",
        "            true_answer = test_dataset['answer'][idx].strip().upper()\n",
        "\n",
        "            # Get model prediction\n",
        "            predicted = predict(text)\n",
        "\n",
        "            # Extract first valid choice letter from prediction\n",
        "            predicted_letter = re.search(r'\\b([A-D])\\b', predicted.upper())\n",
        "            if predicted_letter:\n",
        "                predicted_letter = predicted_letter.group(1)\n",
        "            else:\n",
        "                predicted_letter = None\n",
        "\n",
        "            # Compare with ground truth\n",
        "            if predicted_letter == true_answer:\n",
        "                correct += 1\n",
        "            else:\n",
        "                wrong_samples.append({\n",
        "                    'text': text,\n",
        "                    'predicted': predicted,\n",
        "                    'true': true_answer\n",
        "                })\n",
        "\n",
        "            total += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing sample {idx}: {str(e)}\")\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\n=== Evaluation Results ===\")\n",
        "    print(f\"Correct: {correct}/{total}\")\n",
        "    print(f\"Accuracy: {accuracy:.2%}\")\n",
        "    print(f\"Wrong samples saved in 'wrong_samples' list\")\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'total': total,\n",
        "        'wrong_samples': wrong_samples\n",
        "    }\n",
        "\n",
        "# Usage\n",
        "test_results = evaluate(data['test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JwEcHEmP3xS",
        "outputId": "e91442cb-941d-43d2-ae55-a5490daee276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Sample 1\n",
            "Ground Truth: D\n",
            "Predicted: A) sympathy, because they assume that she is experiencing intense heat for the first time.\n",
            "Passage:\n",
            "This passage is adapted from Mary Helen Stefaniak, The\n",
            "Cailiffs of Baghdad, Georgia: A Novel. ©2010 by Mary Helen\n",
            "Stefaniak.\n",
            "Miss Grace Spivey arrived in Threestep, Georgia,\n",
            "in August 1938. She steppe...\n",
            "\n",
            "--------------------------------------------------\n",
            "### Sample 2\n",
            "Ground Truth: A\n",
            "Predicted: D) Miss Spivey herself.\n",
            "Passage:\n",
            "This passage is adapted from Mary Helen Stefaniak, The\n",
            "Cailiffs of Baghdad, Georgia: A Novel. ©2010 by Mary Helen\n",
            "Stefaniak.\n",
            "Miss Grace Spivey arrived in Threestep, Georgia,\n",
            "in August 1938. She steppe...\n",
            "\n",
            "--------------------------------------------------\n",
            "### Sample 3\n",
            "Ground Truth: C\n",
            "Predicted: A) delighted.\n",
            "Passage:\n",
            "This passage is adapted from Mary Helen Stefaniak, The\n",
            "Cailiffs of Baghdad, Georgia: A Novel. ©2010 by Mary Helen\n",
            "Stefaniak.\n",
            "Miss Grace Spivey arrived in Threestep, Georgia,\n",
            "in August 1938. She steppe...\n",
            "\n",
            "--------------------------------------------------\n",
            "### Sample 4\n",
            "Ground Truth: A\n",
            "Predicted: C) Lines 15-18\n",
            "Passage:\n",
            "This passage is adapted from David Owen, The Conundrum:\n",
            "How Scientific Innovation, Increased Efficiency, and Good\n",
            "Intentions Can Make Our Energy and Climate Problems Worse.\n",
            "©2011 by David Owen.\n",
            "Buildi...\n",
            "\n",
            "--------------------------------------------------\n",
            "### Sample 5\n",
            "Ground Truth: B\n",
            "Predicted: D) environmentally harmful in the short term.\n",
            "Passage:\n",
            "This passage is adapted from David Owen, The Conundrum:\n",
            "How Scientific Innovation, Increased Efficiency, and Good\n",
            "Intentions Can Make Our Energy and Climate Problems Worse.\n",
            "©2011 by David Owen.\n",
            "Buildi...\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for i, sample in enumerate(test_results['wrong_samples'][:5]):\n",
        "    print(f\"### Sample {i+1}\")\n",
        "    print(f\"Ground Truth: {sample['true']}\")\n",
        "    print(f\"Predicted: {sample['predicted']}\")\n",
        "    print(\"Passage:\")\n",
        "    print(extract_sections(sample['text'])['passage'][:200] + \"...\")\n",
        "    print(\"\\n\" + \"-\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIB19R50EzNZ"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"trained-model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FofrEs3QIScD"
      },
      "source": [
        "## **Inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxjoUMCcE0Sb"
      },
      "outputs": [],
      "source": [
        "from peft import PeftConfig, PeftModel\n",
        "\n",
        "def format_inference_prompt(text):\n",
        "    sections = extract_sections(text)\n",
        "    choices_text = '\\n'.join(sections['choices'])\n",
        "\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": LLAMA3_SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\", \"content\": f\"\"\"Read the passage and answer the question.\n",
        "\n",
        "### Passage: {sections['passage']}\n",
        "### Question: {sections['question']}\n",
        "### Choices: {choices_text}\n",
        "\n",
        "Respond with ONLY the letter and full text of the correct answer.\"\"\"}\n",
        "]\n",
        "\n",
        "PEFT_MODEL = \"KoiiVN/llama3-3B-peft-SAT-reading-v2\"\n",
        "\n",
        "# Load config v& model\n",
        "config = PeftConfig.from_pretrained(PEFT_MODEL)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    config.base_model_name_or_path,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "model = PeftModel.from_pretrained(model, PEFT_MODEL)\n",
        "\n",
        "# Tokenizer & generation config\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "generation_config = GenerationConfig(\n",
        "    max_new_tokens=128,\n",
        "    temperature=0.01,\n",
        "    do_sample=False,\n",
        "    repetition_penalty=1.15,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    forced_eos_token_id=tokenizer.eos_token_id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfsLgcIkE2Qm"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Inference loop\n",
        "for i in range(5):\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    input_text = data[\"test\"]['text'][i]\n",
        "    true_answer = data[\"test\"]['answer'][i]\n",
        "\n",
        "    messages = format_inference_prompt(input_text)\n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=False\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs.input_ids,\n",
        "            attention_mask=inputs.attention_mask,\n",
        "            generation_config=generation_config\n",
        "        )\n",
        "\n",
        "    full_output = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "\n",
        "    if \"<|assistant|>\" in full_output:\n",
        "        response = full_output.split(\"<|assistant|>\")[1].replace(\"<|eot_id|>\", \"\").strip()\n",
        "    else:\n",
        "        response = full_output.replace(prompt, \"\").strip()\n",
        "\n",
        "    print(f\"=== Sample {i+1} ===\")\n",
        "    print(f\"[Question]\\n{messages[1]['content']}\")\n",
        "    print(f\"\\n[Ground Truth] {true_answer}\")\n",
        "    print(f\"[Prediction] {response}\")\n",
        "    print(\"\\n\" + \"-\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34Tc-FbfE4Ff"
      },
      "outputs": [],
      "source": [
        "def custom_predict(passage: str, question: str, choices: list):\n",
        "    choices_text = '\\n'.join(choices)\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": LLAMA3_SYSTEM_PROMPT\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Read the passage and answer the question.\n",
        "\n",
        "### Passage:\n",
        "{passage}\n",
        "\n",
        "### Question:\n",
        "{question}\n",
        "\n",
        "### Choices:\n",
        "{choices_text}\n",
        "\n",
        "Respond with ONLY the letter and full text of the correct answer.\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        add_generation_prompt=True,\n",
        "        tokenize=False\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs.input_ids,\n",
        "            attention_mask=inputs.attention_mask,\n",
        "            generation_config=generation_config\n",
        "        )\n",
        "\n",
        "    full_output = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "\n",
        "    if \"<|assistant|>\" in full_output:\n",
        "        response = full_output.split(\"<|assistant|>\")[1].replace(\"<|eot_id|>\", \"\").strip()\n",
        "    else:\n",
        "        response = full_output.replace(prompt, \"\").strip()\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "licD12dKP3xT",
        "outputId": "595a7564-b7cf-40d4-9094-613a9eb44a4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Custom Test Result ===\n",
            "[Prediction] <|begin_of_text|>A) To explain his reluctance to judge others<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "custom_passage = \"\"\"\n",
        "This passage is adapted from F. Scott Fitzgerald, The Great Gatsby.\n",
        "\"In my younger and more vulnerable years my father gave me some advice that I’ve been turning over in my mind ever since. ‘Whenever you feel like criticizing anyone,’ he told me, ‘just remember that all the people in this world haven’t had the advantages that you’ve had.’ He didn’t say any more, but we’ve always been unusually communicative in a reserved way, and I understood that he meant a great deal more than that. In consequence, I’m inclined to reserve all judgments, a habit that has opened up many curious natures to me and also made me the victim of not a few veteran bores.\"\n",
        "\"\"\"\n",
        "\n",
        "custom_question = \"What is the primary purpose of the narrator’s recollection of his father’s advice?\"\n",
        "custom_choices = [\n",
        "    \"A) To explain his reluctance to judge others\", #A is correct, just test\n",
        "    \"B) To highlight his privileged upbringing\",\n",
        "    \"C) To criticize his father’s moral values\",\n",
        "    \"D) To foreshadow future conflicts in the story\"\n",
        "]\n",
        "\n",
        "prediction = custom_predict(custom_passage, custom_question, custom_choices)\n",
        "print(\"\\n=== Custom Test Result ===\")\n",
        "print(\"[Prediction]\", prediction)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "itune-ielts",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
